i=i+1
temp <- cohort[sample(nrow(cohort)) < 101,]
pairs <- combn(100,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(cohort[pairs[,x],], nts)))
i=i+1
temp <- cohort[sample(nrow(cohort)) < 101,]
pairs <- combn(100,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(cohort[pairs[,x],], nts)))
i=i+1
sample.list
temp <- cohort[sample(nrow(cohort)) < 101,]
temp
sample(nrow(cohort))
cycles
nts
bootstrap_sample(cohort, cycles, nts = )
cohort
bootstrap_sample(cohort, cycles, nts = )
nts
bootstrap_sample(cohort, cycles, nts = nts)
x <- bootstrap_sample(cohort, cycles, nts = nts)
x
ntd_pair <- function(pair, nts) {
sum(xor(pair[1,], pair[2,]))/nts
}
ntd_pair(rbind(c(1,0,1),c(0,0,0)),nts)
2/nts
simul_cohort(freq,10)
freq
sum(freq)
cohort <- simul_cohort(freq,10)
colSums(cohort)
colMeans(cohort)
freq
plot(freq)
points(colSums(cohort))
points(colMeans(cohort))
points(colMeans(cohort), col = 'red')
cohort <- simul_cohort(freq,10000)
points(colMeans(cohort), col = 'red')
plot(freq)
points(colMeans(cohort), col = 'red')
colMeans(cohort)
plot(colMeans(cohort))
rbinom(10, 1, prob = freq)
frq
freq
rbinom(77, 1, prob = freq)
rbinom(77, 1, prob = freq)
rbinom(77, 1, prob = freq)
rbinom(77, 1, prob = freq)
s
size
simul_cohort <- function(freq, size) {
sapply(size, function(x) rbinom(length(prob), 1, prob = freq))
}
simul_cohort(freq, 100)
simul_cohort <- function(freq, size) {
sapply(1:size, function(x) rbinom(length(prob), 1, prob = freq))
}
simul_cohort(freq, 100)
freq
?rbinom()
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,1))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,1))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(10,1,c(0,0,0,0,0,0,0,0,0,.5))
rbinom(20,1,c(0,0,0,0,0,0,0,0,0,1))
rbinom(20,1,c(0,0,0,0,0,0,0,0,0,1))
rbinom(20,1,c(0,0,0,0,0,0,0,0,0,1))
rbinom(20,1,c(0,0,0,0,0,0,0,0,0,1))
rbinom(20,1,c(0,0,0,0,0,0,0,0,0,1))
simul_cohort <- function(freq, size) {
sapply(1:size, function(x) rbinom(length(freq), 1, prob = freq))
}
cohort <- simul_cohort(freq,10000)
dim(cohort)
size
simul_cohort <- function(freq, size) {
t(sapply(1:size, function(x) rbinom(length(freq), 1, prob = freq)))
}
cohort <- simul_cohort(freq,10000)
dim(cohort)
ntd_pair(rbind(c(1,0,1),c(0,0,0)),nts)
bootstrap_sample <- function(cohort, cycles, nts) {
sample.list <- rep(NA, cycles)
for (i in 1:cycles) {
temp <- cohort[sample(nrow(cohort)) < 101,]
pairs <- combn(100,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(cohort[pairs[,x],], nts)))
}
sample.list
}
temp5 <- bootstrap_sample(cohort, 10, nts)
temp5
sample(nrow(cohort)) < 101
plot(sample(nrow(cohort)) < 101)
plot(sample(nrow(cohort)) < 101)
plot(sample(nrow(cohort)) < 101)
plot(sample(nrow(cohort)) < 101)
plot(sample(nrow(cohort)) < 101)
plot(sample(nrow(cohort)) < 101)
plot(sample(nrow(cohort)) < 101)
temp5 <- bootstrap_sample(cohort, 100, nts)
temp5
bootstrap_sample <- function(cohort, cycles, nts) {
chunk <- 10
sample.list <- rep(NA, cycles)
for (i in 1:cycles) {
temp <- cohort[sample(nrow(cohort)) < chunk + 1,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(cohort[pairs[,x],], nts)))
}
sample.list
}
temp5 <- bootstrap_sample(cohort, 100, nts)
temp5
bootstrap_sample <- function(cohort, cycles, nts) {
chunk <- 5
sample.list <- rep(NA, cycles)
for (i in 1:cycles) {
temp <- cohort[sample(nrow(cohort)) < chunk + 1,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(cohort[pairs[,x],], nts)))
}
sample.list
}
temp5
temp5 <- bootstrap_sample(cohort, 100, nts)
temp5
bootstrap_sample <- function(cohort, cycles, nts) {
chunk <- 100
sample.list <- rep(NA, cycles)
for (i in 1:cycles) {
temp <- cohort[sample(nrow(cohort)) < chunk + 1,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(temp[pairs[,x],], nts)))
}
sample.list
}
temp5 <- bootstrap_sample(cohort, 100, nts)
temp5
plot(temp5)
mean(temp5)
abline(h=mean(temp5))
temp5 <- bootstrap_sample(cohort, 100, 100, nts)
bootstrap <- function(cohort, cycles, chunk, nts) {
sample.list <- rep(NA, cycles)
for (i in 1:cycles) {
temp <- cohort[sample(nrow(cohort)) < chunk + 1,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(temp[pairs[,x],], nts)))
}
sample.list
}
temp5 <- bootstrap_sample(cohort, 100, 100, nts)
bootstrap <- function(cohort, cycles, chunk, nts) {
sample.list <- rep(NA, cycles)
for (i in 1:cycles) {
temp <- cohort[sample(nrow(cohort)) < chunk + 1,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(temp[pairs[,x],], nts)))
}
sample.list
}
temp5 <- bootstrap_sample(cohort, 100, 100, nts)
nts
ntd_simul <- function(cohort, cycles, chunk, nts) {
sample.list <- rep(NA, cycles)
for (i in 1:cycles) {
temp <- cohort[sample(nrow(cohort)) < chunk + 1,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(temp[pairs[,x],], nts)))
}
sample.list
}
ntd_simul(simul_cohort(freq,10000), 100, 100, nts)
plot(.Last.value)
ntd_simul <- function(cohort, cycles, chunk, nts) {
sample.list <- rep(NA, cycles)
touch <- rep(0,nrow(cohort))
for (i in 1:cycles) {
x <- sample(nrow(cohort)) < chunk + 1
touch <- touch | x
temp <- cohort[x,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(temp[pairs[,x],], nts)))
}
list(sample.list,
}
ntd_simul <- function(cohort, cycles, chunk, nts) {
sample.list <- rep(NA, cycles)
touch <- rep(0,nrow(cohort))
for (i in 1:cycles) {
x <- sample(nrow(cohort)) < chunk + 1
touch <- touch | x
temp <- cohort[x,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(temp[pairs[,x],], nts)))
}
list(sample.list, touch)
}
ntd_simul(simul_cohort(freq,10000), 100, 100, nts)
temp <- .Last.value
temp[[1]]
plot(temp[[1]])
plot(temp[[2]])
mean(temp[[2]])
ntd_simul <- function(cohort, cycles, chunk, nts) {
sample.list <- rep(NA, cycles)
touch <- rep(0,nrow(cohort))
for (i in 1:cycles) {
cut <- sample(nrow(cohort)) < chunk + 1
touch <- touch | cut
temp <- cohort[cut,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(temp[pairs[,x],], nts)))
}
list(sample.list, touch)
}
cohort <- simul_cohort(data.mybpc3[[4]]$Freq,10000)
simul_cohort <- function(freq, size) {
t(sapply(1:size, function(x) rbinom(length(freq), 1, prob = freq)))
}
cohort <- simul_cohort(data.mybpc3[[4]]$Freq,10000)
output
ntd_simul <- function(cohort, cycles, chunk, nts) {
sample.list <- rep(NA, cycles)
touch <- rep(0,nrow(cohort))
for (i in 1:cycles) {
cut <- sample(nrow(cohort)) < chunk + 1
touch <- touch | cut
temp <- cohort[cut,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(temp[pairs[,x],], nts)))
}
#list(sample.list, touch)
sample.list
}
output <- sapply(data.mybpc3, function(x) ntd_simul(simul_cohort(x$Freq,10000), 20, 100, nts.mybpc3))
output <- rbind(colMeans(output), max(output)-min(output))
rownames(output) <- c("Mean", "Range")
output
# James Diao
# June 20, 2016
library(RMySQL)
library(shiny)
setwd("/Users/jamesdiao/Documents/Kohane_Lab/Week_1/")
all_cons <- dbListConnections(MySQL())
for (con in all_cons)
dbDisconnect(con)
con <- dbConnect(MySQL(), user = 'root',
password = 'root', dbname = 'kohane_lab', host = 'localhost',
unix.sock = "/Applications/MAMP/tmp/mysql/mysql.sock")
query <- "select Position, Allele_Count,Allele_Number,Allele_Frequency,
Allele_Count_African, Allele_Number_African,
Allele_Count_East_Asian, Allele_Number_East_Asian,
Allele_Count_European_Non_Finnish, Allele_Number_European_Non_Finnish,
Allele_Count_Finnish, Allele_Number_Finnish,
Allele_Count_Latino, Allele_Number_Latino,
Allele_Count_Other, Allele_Number_Other,
Allele_Count_South_Asian, Allele_Number_South_Asian from"
input.mybpc3 <- dbGetQuery(con, paste(query,"MYBPC3"))
input.myh7 <- dbGetQuery(con, paste(query,"MYH7"))
#nts.gene = number of nts in that gene
#Assumption: nts = range in chromosomal positions
nts.mybpc3 <- max(input.mybpc3$Position)-min(input.mybpc3$Position)+1
nts.myh7 <- max(input.myh7$Position)-min(input.myh7$Position)+1
# Takes ancestry (African) and gene dataset input (input.MYBPC3) and outputs "Position, Count, Number, Freq"
# This also adds all counts from duplicate positions (totals appear to be the same across duplicates).
process <- function(ancestry, gene.input) {
#Collect and name ancestry-specific columns
out <- data.frame(gene.input["Position"],
gene.input[paste("Allele_Count_", ancestry, sep = "")],
gene.input[paste("Allele_Number_", ancestry, sep = "")])
colnames(out) <- c("Position", "Count", "Number")
#Collect nonunique items
pos_table <- table(out$Position)
nonunique <- names(pos_table)[pos_table>1]
#create add_on = all duplicates that have been combined into a single data frame
add_on <- as.data.frame(t(sapply(nonunique, function(x)
c(sum(out$Count[out$Position==x]),
mean(out$Number[out$Position==x])))))
add_on <- cbind(rownames(add_on), add_on)
colnames(add_on) <- colnames(out)
#remove all duplicates
out <- out[!(out$Position %in% nonunique),]
#add combined duplicates back in
out <- rbind(out, add_on)
#remove all variants that have 0 counts
out <- out[out$Count!=0,]
rownames(out) <- NULL
#calculate and append Freq = count/number
out$Freq <- out$Count/out$Number
out
}
#Extract data for MYBPC3 and MYH7
ancestries <- c("African", "East_Asian", "European_Non_Finnish", "Finnish","Latino","Other","South_Asian")
data.mybpc3 <- lapply(ancestries, function(x) process(x, input.mybpc3))
data.myh7 <- lapply(ancestries, function(x) process(x, input.myh7))
names(data.mybpc3) = names(data.myh7) = c("Afr", "E.Asian", "NFE", "Finnish","Latino","Other","S.Asian")
#Plot the number of unique variants
counts <- rbind(sapply(data.mybpc3, nrow),sapply(data.myh7, nrow))
rownames(counts) <- c("MYBPC3","MYH7")
bp <- barplot(counts, ylim = c(0,max(apply(counts,2,sum))*1.2), main = "Unique Variant Counts by Ethnicity",
ylab = "Number of Unique Variants", col = c("Black","Red"), beside = T)
text(bp, counts, counts, pos = 3)
legend("topright",c("MYBPC3","MYH7"), pch = 19, col = c("Black","Red"))
#Looks like there's on avg 4-5 counts/chromosome
counts_per_chr <- sum(input.mybpc3$Allele_Count)/mean(input.mybpc3$Allele_Number)
#Assume independence
#Multiple all pairs of sequence probabilities, multiply by 1/nts
#Sum these up
ntd_one_per <- function(freq, nts) {
freq <- freq/sum(freq)
2*sum(apply(combn(freq,2),2,prod))*2/nts
}
#Calculate nucleotide diversity for mybpc3
ntd.mybpc3 <- sapply(data.mybpc3, function(x) ntd_one_per(x$Freq,nts.mybpc3))
ntd.myh7 <- sapply(data.myh7, function(x) ntd_one_per(x$Freq,nts.myh7))
ntd.1 <- rbind(ntd.mybpc3, ntd.myh7)
bp <- barplot(ntd.1, ylim = c(0,max(ntd.1)*1.3), main = "Unique Variant Counts by Ethnicity",
ylab = "Number of Unique Variants", col = c("Black","Red"), beside = T)
legend("topright",c("MYBPC3","MYH7"), pch = 19, col = c("Black","Red"))
ntd.1
#Takes around 1.5 seconds
system.time(sapply(data.mybpc3, function(x) ntd_one_per(x$Freq,nts.mybpc3)))
#For testing purposes
freq <- data.mybpc3[[4]]$Freq
nts <- nts.mybpc3
#sum(apply(combn(freq,4),2,prod))*4/nts + sum(apply(combn(freq,3),2,prod))*3/nts + sum(apply(combn(freq,2),2,prod))*2/nts
#m <- 1
#nt_diversity <- -(1-2*m/nts)/nts*log(sum(apply(combn(freq,4)^2,2,prod)))/nts
#nt_diversity
pi.avg <- function(nts, m) {
sapply(0:m, function(i) (2*m-i)/nts)
}
pi.weights <- function(n, m) {
sapply(0:m, function(i)
choose(n, 2*m-i)*
choose(2*m-i, i)
)
}
#from n, pick m, with m possible overlaps
pi.est <- function (nts, n, m) {
sum(pi.avg(nts,m)*pi.weights(n,m))/sum(pi.weights(n,m))
}
### Calculating nucleotide diversity - Part 2
ntd_m_per <- function(freq, nts, m) {
freq <- freq/sum(freq)
2*pi.est(nts,length(freq),m)*sum(apply(combn(freq,2*m),2,prod))
}
ntd.mybpc3 <- sapply(data.mybpc3, function(x) ntd_m_per(x$Freq, nts.mybpc3, 1))
ntd.myh7 <- sapply(data.myh7, function(x) ntd_m_per(x$Freq, nts.myh7, 1))
ntd.m.2 <- rbind(ntd.mybpc3, ntd.myh7)
#Correlation for mybpc3
cor(ntd.1[1,], ntd.m.2[1,])
#Correlation for myh7
cor(ntd.1[2,], ntd.m.2[2,])
# For m = 2 and 77  variants (Fin), we need to sum up choose(77 , 4) values = 1.5 million
# For m = 2 and 340 variants (Afr), we need to sum up choose(340, 4) values = 500 million.
# For m = 2 and 850 variants (NFE), we need to sum up choose(850, 4) values = 20,000 million.
ntd_simul <- function(cohort, cycles, chunk, nts) {
sample.list <- rep(NA, cycles)
touch <- rep(0,nrow(cohort))
for (i in 1:cycles) {
cut <- sample(nrow(cohort)) < chunk + 1
touch <- touch | cut
temp <- cohort[cut,]
pairs <- combn(chunk,2)
sample.list[i] <- mean(sapply(seq(ncol(pairs)), function(x) ntd_pair(temp[pairs[,x],], nts)))
}
#list(sample.list, touch)
sample.list
}
output <- sapply(data.mybpc3, function(x) ntd_simul(simul_cohort(x$Freq,10000), 20, 100, nts.mybpc3))
ntd_pair <- function(pair, nts) {
sum(xor(pair[1,], pair[2,]))/nts
}
#ntd_pair(rbind(c(1,0,1),c(0,0,0)),nts.mybpc3)
simul_cohort <- function(freq, size) {
t(sapply(1:size, function(x) rbinom(length(freq), 1, prob = freq)))
}
output <- sapply(data.mybpc3, function(x) ntd_simul(simul_cohort(x$Freq,10000), 20, 100, nts.mybpc3))
output <- rbind(colMeans(output), max(output)-min(output))
rownames(output) <- c("Mean", "Range")
output
x <- output[1,]
avg <- output[1,]
plot(1:7, avg)
plot(1:7, avg,
ylim=range(c(avg-sdev, avg+sdev)),
pch=19, xlab="Measurements", ylab="Mean +/- SD",
main="Scatter plot with std.dev error bars"
)
sdev <- output[2,]
plot(1:7, avg,
ylim=range(c(avg-sdev, avg+sdev)),
pch=19, xlab="Measurements", ylab="Mean +/- SD",
main="Scatter plot with std.dev error bars"
)
# hack: we draw arrows but with very special "arrowheads"
arrows(x, avg-sdev, x, avg+sdev, length=0.05, angle=90, code=3)
arrows(x, avg-sdev, x, avg+sdev, length=0.05, angle=90, code=3)
plot(1:7, avg,
ylim=range(c(avg-sdev, avg+sdev)),
xlab="Measurements", ylab="Mean +/- SD",
main="Scatter plot with std.dev error bars"
)
# hack: we draw arrows but with very special "arrowheads"
arrows(x, avg-sdev, x, avg+sdev, length=0.05, angle=90, code=3)
sdev
avg
arrows(x, 10*(avg-sdev), x, avg+sdev, length=0.05, angle=90, code=3)
arrows(x, 100*(avg-sdev), x, avg+sdev, length=0.05, angle=90, code=3)
arrows(x, 1000*(avg-sdev), x, avg+sdev, length=0.05, angle=90, code=3)
arrows(x, 10000*(avg-sdev), x, avg+sdev, length=0.05, angle=90, code=3)
output
sd(output[1])
sd(output[1,])
output
plot(output[1,])
plot(output[1,], ylim = c(0,0.01))
plot(output[1,], ylim = c(0,max(output[1,])))
plot(output[1,], ylim = c(0,1.5*max(output[1,])))
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(output[1,]+output[2,], output[1,]+output[2,])
points(1:7, output[1,]+output[2,])
points(c(1:7)*1.5-1, output[1,]+output[2,])
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(c(1:7)*1.5-1, output[1,]+output[2,])
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(c(1:7)*1.4-.8, output[1,]+output[2,])
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(c(1:7)*1.45-.8, output[1,]+output[2,])
points(c(1:7)*1.3-.8, output[1,]+output[2,])
points(c(1:7)*1.3-.8, output[1,]+output[2,])
output
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(c(1:7)*1.3-.8, output[1,]+output[2,])
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(c(1:7)*1.2-.5, output[1,]+output[2,])
points(c(1:7)*1.2-.5, output[1,]+output[2,])
points(c(1:7)*1.2-.5, output[1,]-output[2,])
?line
?arrows
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(c(1:7)*1.2-.5, output[1,]+output[2,])
points(c(1:7)*1.2-.5, output[1,]-output[2,])
text(c(1:7)*1.2-.5, 0, output[1,])
text(c(1:7)*1.2-.5, 0, round(output[1,],4)
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(c(1:7)*1.2-.5, output[1,]+output[2,])
points(c(1:7)*1.2-.5, output[1,]-output[2,])
text(c(1:7)*1.2-.5, 0, round(output[1,],4)
text(c(1:7)*1.2-.5, 0, round(output[1,],4))
text(c(1:7)*1.2-.5, 0, round(output[1,],4))
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(c(1:7)*1.2-.5, output[1,]+output[2,])
points(c(1:7)*1.2-.5, output[1,]-output[2,])
text(c(1:7)*1.2-.5, 0, round(output[1,],4))
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(c(1:7)*1.2-.5, output[1,]+output[2,])
points(c(1:7)*1.2-.5, output[1,]-output[2,])
text(c(1:7)*1.2-.5, .00005, round(output[1,],4))
barplot(output[1,], ylim = c(0,1.5*max(output[1,])))
points(c(1:7)*1.2-.5, output[1,]+output[2,])
points(c(1:7)*1.2-.5, output[1,]-output[2,])
text(c(1:7)*1.2-.5, .00002, round(output[1,],4))
text(c(1:7)*1.2-.5, 0, round(output[1,],4))
output[2,]
